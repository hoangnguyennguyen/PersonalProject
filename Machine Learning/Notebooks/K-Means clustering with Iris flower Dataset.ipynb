{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using K-Mean for Iris Flower clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    iris_data.data, columns=iris_data.feature_names\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "transformed_df = pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(X, centroids_list):    \n",
    "    '''\n",
    "        Input:\n",
    "            - X: Data point\n",
    "            - centroids_list: List of centroids\n",
    "            \n",
    "        Output:\n",
    "            Distance from Data point to centroids\n",
    "            \n",
    "        How this Function work:\n",
    "            For each centroid, compute the euclidean distance, then append to dis list\n",
    "    '''\n",
    "    dis: list = []\n",
    "    for centroid in centroids_list:\n",
    "        dis.append(np.sum(np.square(X - centroid)))\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_label(X, centroids_list):\n",
    "\n",
    "    '''\n",
    "        Input: \n",
    "            - X: Data point\n",
    "            - centroids_list: List of centroids\n",
    "            \n",
    "        Output: \n",
    "            [1]: True if the label was updated\n",
    "            [2]: The data point\n",
    "            \n",
    "        How this Function work:\n",
    "            Line 18: Compute the distance from data point to each centroid\n",
    "            Line 19: Find the label which has min distance to data point\n",
    "            Line 21-23: Check if new nearest centroid change, then update\n",
    "    '''\n",
    "    re = False\n",
    "    # Compute distance fron data point to centroids\n",
    "    dis = distance(X[:-1], centroids_list)\n",
    "    new_label = np.argmin(dis)\n",
    "    if new_label != int(X[-1]):\n",
    "        X[-1] = new_label\n",
    "        re = True\n",
    "        \n",
    "    return re, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WCV(X):\n",
    "    '''\n",
    "        Input:\n",
    "            - X: Set of data points in the same cluster\n",
    "        \n",
    "        Output:\n",
    "            Within Cluster Variance\n",
    "            \n",
    "        How this Function work:\n",
    "            Compute the sum of distance of two data point for each feature after squared. Then divided by Cluster set size\n",
    "    '''\n",
    "    total_sum = 0\n",
    "    for first_point in X:\n",
    "        for second_point in X:\n",
    "            total_sum += np.sum(np.square(first_point - second_point), axis=0)\n",
    "            \n",
    "    return total_sum / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def k_mean_cluster(X: np.ndarray, k_clusters: int):\n",
    "    '''\n",
    "        Input:\n",
    "            - X: Numerical data has shape (D, N) where N is number of samples and D is number of features\n",
    "            - k_clusters: number of clusters for clustering\n",
    "    \n",
    "        Output:\n",
    "            Matrix R has shape (N, D + 1) where N is number of samples, D features and 1 label colums for cluster\n",
    "            \n",
    "        Variables:\n",
    "            - lables: Random label \n",
    "            - Result: Whole data set add 1 label column\n",
    "            - Cost_per_iter: total WCV for each iteration\n",
    "            - is_re_label: Check whether any data point was re labeled\n",
    "            - iter: iteration\n",
    "            - cluster_set: Set of data points have the same label\n",
    "            - centroids_list: List of centroids\n",
    "        \n",
    "        How this Function work:\n",
    "            Line 34 - 35: Assign random labels for dataset with Uniform distribution\n",
    "            Line 43 - 36: Modify centroid position for each cluster\n",
    "            Line 51 - 56: Relabel after centroids position have changed\n",
    "            Line 59 - 61: Compute the total WCF for current iteration \n",
    "            \n",
    "    '''\n",
    "    \n",
    "    cost_per_iter = []\n",
    "    is_re_label = True\n",
    "    centroids_list = np.zeros(shape=(k_clusters, X.shape[0]))\n",
    "    iter = 0\n",
    "    \n",
    "    # Assignments\n",
    "    labels = np.random.choice(k_clusters, X.shape[1]).reshape(1, -1)\n",
    "    result = np.r_[X, np.array(labels)]\n",
    "\n",
    "    while is_re_label:\n",
    "        is_re_label = False\n",
    "        iter += 1\n",
    "        # Compute Centroids\n",
    "        for cluster in range(k_clusters):\n",
    "            # Cluster_set has shape (D, Ck) where D is the number of features and Ck is the number of points in cluster K\n",
    "            cluster_set = result.T[result[-1, :] == float(cluster)][:, :-1].T\n",
    "            \n",
    "            # Centroids_list[cluster] has D float numberz for D features\n",
    "            centroids_list[cluster] = cluster_set.mean(axis=1)\n",
    "            \n",
    "\n",
    "        # Relabel\n",
    "        \n",
    "        for i in range(X.shape[1]):\n",
    "            # Re is True if point ith assigned new label\n",
    "            re, result[:, i] = re_label(result[:, i], centroids_list)\n",
    "            \n",
    "            if re:\n",
    "                is_re_label = True\n",
    "\n",
    "        cost_per_iter.append(0)\n",
    "        for cluster in range(k_clusters):\n",
    "            cluster_set = result.T[result[-1, :] == float(cluster)][:, :2]\n",
    "            cost_per_iter[-1] += WCV(cluster_set)\n",
    "        \n",
    "    return result, centroids_list, iter, cost_per_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, centroids, iter, cost_per_iter = k_mean_cluster(transformed_df.T, 3)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 12))\n",
    "\n",
    "g = sns.scatterplot(x=result[0], y=result[1], hue=result[2].astype(int), palette='Set2', ax=axes[0], s=60)\n",
    "g.set_title(\"Transformed Data clustered by K-Means\")\n",
    "g = sns.lineplot(x=range(iter), y=cost_per_iter, ax=axes[1])\n",
    "g.set_title(\"Within Cluster Variance change through iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "temp = transformed_df.copy()\n",
    "kmean = KMeans(n_clusters=3).fit(temp)\n",
    "clusters = kmean.predict(temp)\n",
    "\n",
    "sk_result = {\n",
    "    'X1': temp[:, 0],\n",
    "    'X2': temp[:, 1],\n",
    "    'cluster': clusters\n",
    "}\n",
    "\n",
    "sk_result = pd.DataFrame(sk_result)\n",
    "plt.figure(figsize=(12, 6))\n",
    "g = sns.scatterplot(x=sk_result.X1, y=sk_result.X2, hue=sk_result.cluster.astype(int), palette='Set2', s=60)\n",
    "g.set_title(\"Transformed Data clustered by K-Means (Sklearn)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Centroids Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_centroids = kmean.cluster_centers_\n",
    "kmean_centroids.sort(axis=0)\n",
    "centroids.sort(axis=0)\n",
    "\n",
    "mean_square_error = np.mean((centroids - kmean_centroids) ** 2)\n",
    "print(f\"{mean_square_error = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "g = sns.scatterplot(x=result[0], y=result[1], hue=result[2].astype(int), palette='Set2', s=60, ax=axes[0])\n",
    "g.set_title(\"Self-define\")\n",
    "\n",
    "\n",
    "g = sns.scatterplot(x=sk_result.X1, y=sk_result.X2, hue=sk_result.cluster.astype(int), palette='Set2', s=60, ax=axes[1]);\n",
    "g.set_title(\"Sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
